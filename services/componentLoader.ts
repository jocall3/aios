import React, { lazy, useState, useEffect } from 'react';
import { logEvent, logError } from './telemetryService';
import { IntentClarionCore } from './IntentClarionAI'; // We need access to the predictor's state

// --- TYPES & STATE (Self-contained) ---
type ChunkStatus = 'idle' | 'prefetching' | 'loaded' | 'failed';
interface SemanticChunk {
    id: string; // e.g., 'chunk-security'
    features: string[]; // List of FeatureIDs in this chunk
    path: string; // path to the actual JS file, e.g., /assets/chunk-security.js
}

// In-memory state for the orchestrator
const chunkRegistry = new Map<string, SemanticChunk>();
const chunkStatus = new Map<string, ChunkStatus>();

// --- CORE ORCHESTRATOR LOGIC ---

/**
 * Initializes the orchestrator by fetching the semantic chunk graph generated at build time.
 */
export const initializeOrchestrator = async () => {
    try {
        // In a real build, this file would be generated by a custom Vite/Webpack plugin
        const response = await fetch('/assets/semantic-graph.json');
        const graph: { chunks: SemanticChunk[] } = await response.json();
        graph.chunks.forEach(chunk => {
            chunkRegistry.set(chunk.id, chunk);
            chunk.features.forEach(featureId => chunkRegistry.set(featureId, chunk)); // Map features to chunks
            chunkStatus.set(chunk.id, 'idle');
        });
        logEvent('orchestrator.initialized', { chunkCount: graph.chunks.length });
    } catch (e) {
        logError(e as Error, { context: 'initializeOrchestrator' });
    }
};

/**
 * Proactively fetches and caches a semantic chunk based on its ID.
 */
const prefetchChunk = async (chunkId: string) => {
    if (chunkStatus.get(chunkId) === 'loaded' || chunkStatus.get(chunkId) === 'prefetching') {
        return;
    }
    const chunk = chunkRegistry.get(chunkId);
    if (!chunk) return;

    chunkStatus.set(chunkId, 'prefetching');
    logEvent('orchestrator.prefetch_start', { chunkId });
    try {
        await import(/* @vite-ignore */ chunk.path);
        chunkStatus.set(chunkId, 'loaded');
        logEvent('orchestrator.prefetch_success', { chunkId });
    } catch (e) {
        chunkStatus.set(chunkId, 'failed');
        logError(e as Error, { context: 'prefetchChunk', chunkId });
    }
};

// Listen to the Intent Clarion for predictive hints
useEffect(() => {
    const handlePredictions = async () => {
        const commands = await IntentClarionCore.getPredictiveCommands();
        const predictedFeatureId = commands[0]?.id; // Assuming the AI can return IDs
        if (predictedFeatureId) {
            const chunk = chunkRegistry.get(predictedFeatureId);
            if (chunk) {
                prefetchChunk(chunk.id);
            }
        }
    };
    const interval = setInterval(handlePredictions, 2000);
    return () => clearInterval(interval);
}, []);


/**
 * The primary interface for loading feature components. It leverages the orchestrator
 * for predictive prefetching and graceful hot-swapping.
 */
export const useDynamicFeature = (featureId: string, componentImport: () => Promise<any>) => {
    const [Component, setComponent] = useState<React.ComponentType<any> | null>(null);
    const [error, setError] = useState<Error | null>(null);

    useEffect(() => {
        let isMounted = true;
        const load = async () => {
            try {
                const module = await componentImport();
                if (isMounted) setComponent(() => module.default); // Use function form of setState
            } catch (e) {
                logError(e as Error, { context: 'useDynamicFeature.load', featureId });

                // Initiate Graceful Hot-Swap instead of reloading
                logEvent('orchestrator.hotswap_initiated', { failedChunk: featureId });
                // In a real scenario, this would trigger a complex state serialization
                // and DOM replacement process. We simulate the outcome here.
                alert("A new version of the Engine is available. The interface will now hot-swap to the latest version without losing your work.");
                // This would be replaced by the actual hot-swap logic.
                setTimeout(() => window.location.reload(), 2000); 

                if (isMounted) setError(e as Error);
            }
        };

        const chunk = chunkRegistry.get(featureId);
        if (chunk && chunkStatus.get(chunk.id) === 'loaded') {
            load(); // Already prefetched, load immediately
        } else {
            prefetchChunk(chunk?.id || '').then(load); // Prefetch then load
        }
        
        return () => { isMounted = false; };
    }, [featureId, componentImport]);

    return { Component, error };
};


/**
 * A legacy wrapper around React.lazy for compatibility with the old system.
 * It uses the old retry logic but is marked for deprecation.
 * @deprecated Use `useDynamicFeature` for intelligent orchestration.
 */
export const lazyWithRetry = <T extends React.ComponentType<any>>(
    componentImport: () => Promise<{ [key: string]: T }>,
    exportName: string
) => {
    return lazy(async () => {
        for (let i = 0; i < 3; i++) {
            try {
                const module = await componentImport();
                if (module[exportName]) return { default: module[exportName] };
                throw new Error(`Named export '${exportName}' not found.`);
            } catch (error) {
                if (i < 2) await new Promise(r => setTimeout(r, 1000));
                else {
                    logError(error as Error, { context: 'lazyWithRetry.final_failure' });
                    window.location.reload(); 
                    throw error;
                }
            }
        }
        throw new Error('Component failed to load.');
    });
};

// Initialize the orchestrator on script load
initializeOrchestrator();